{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_STATE = 1220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_local = './toxic_comments.csv'\n",
    "data_path_web = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(data_path_local):\n",
    "    df = pd.read_csv(data_path_local, index_col=[0], parse_dates=[0])\n",
    "elif requests.head(data_path_web).status_code == 200:\n",
    "    df = pd.read_csv(data_path_web, index_col=[0], parse_dates=[0])\n",
    "else:\n",
    "    print('Somthing is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159446</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159447</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159450</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159446  \":::::And for the second time of asking, when ...      0\n",
       "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159449  And it looks like it was actually you who put ...      0\n",
       "159450  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159292 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143106\n",
       "1     16186\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot([len(s) for s in df.text], bins=100)\n",
    "plt.title('Sentence Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  5000\n"
     ]
    }
   ],
   "source": [
    "max_len = max([len(sent) for sent in df.text])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                   df['toxic'].values,\n",
    "                                                   test_size = 0.15,\n",
    "                                                   random_state = RANDOM_STATE,\n",
    "                                                   stratify = df['toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic data_type\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   not_set\n",
       "1  D'aww! He matches this background colour I'm s...      0   not_set\n",
       "2  Hey man, I'm really not trying to edit war. It...      0   not_set\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   not_set\n",
       "4  You, sir, are my hero. Any chance you remember...      0   not_set"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set'] * df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>121640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>21466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>13758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text\n",
       "toxic data_type        \n",
       "0     train      121640\n",
       "      val         21466\n",
       "1     train       13758\n",
       "      val          2428"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['toxic', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (4.38.2)\n",
      "Requirement already satisfied: filelock in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sergeidolin/anaconda3/envs/ds_practicum_env/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                         do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].text.values,\n",
    "                                                add_special_tokens = True,\n",
    "                                                return_attention_mask = True,\n",
    "                                                pad_to_max_length = True,\n",
    "                                                max_length = 150,\n",
    "                                                return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_val = tokenizer.batch_encode_plus(df[df.data_type == 'val'].text.values,\n",
    "                                                #add_special_tokens = True,\n",
    "                                                return_attention_mask = True,\n",
    "                                                pad_to_max_length = True,\n",
    "                                                max_length = 150,\n",
    "                                                return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7526,  2339,  ...,     0,     0,     0],\n",
       "        [  101,  4931,  2158,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  2062,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 13183,  6290,  ...,     0,     0,     0],\n",
       "        [  101,  1998,  2009,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  1998,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == 'train'].toxic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode val set\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "\n",
    "#convert data type to torch.tensor\n",
    "labels_val = torch.tensor(df[df.data_type == 'val'].toxic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  7526,  2339,  ...,     0,     0,     0],\n",
       "        [  101,  4931,  2158,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  2062,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 13183,  6290,  ...,     0,     0,     0],\n",
       "        [  101,  1998,  2009,  ...,     0,     0,     0],\n",
       "        [  101,  1000,  1998,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 0, 0, 0])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, \n",
    "                             attention_masks_val, \n",
    "                             labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135398\n",
      "23894\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x17b5e5730>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  7526,  2339,  ...,     0,     0,     0],\n",
       "         [  101,  4931,  2158,  ...,     0,     0,     0],\n",
       "         [  101,  1000,  2062,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 13183,  6290,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  2009,  ...,     0,     0,     0],\n",
       "         [  101,  1000,  1998,  ...,     0,     0,     0]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([0, 0, 0,  ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "#load pre-trained BERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels = 2,\n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 4 #since we have limited resource\n",
    "\n",
    "#load train set\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "#load val set\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                              sampler = RandomSampler(dataset_val),\n",
    "                              batch_size = 32) #since we don't have to do backpropagation for this step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "epochs = 10\n",
    "\n",
    "#load optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr = 1e-5,\n",
    "                 eps = 1e-8) #2e-5 > 5e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps = 0,\n",
    "                                           num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#f1 score\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in {'0':0, '1':1}}\n",
    "    \n",
    "    #make prediction\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "\n",
    "    #evaluation mode disables the dropout layer \n",
    "    model.eval()\n",
    "    \n",
    "    #tracking variables\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(DEVICE) for b in batch)\n",
    "        \n",
    "        #define inputs\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        #compute logits\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        #compute loss\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        #compute accuracy\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    #compute average loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = RANDOM_STATE\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df553b9099a40ad842583a5f5c8ef60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1230789791ac4b20bbeef5491c15cbf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "\n",
    "    #set model in train mode\n",
    "    model.train()\n",
    "\n",
    "    #tracking variable\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    #set up progress bar\n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc='Epoch {:1d}'.format(epoch), \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        #set gradient to 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(DEVICE) for b in batch)\n",
    "\n",
    "        #define inputs\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0] #output.loss\n",
    "        loss_train_total +=loss.item()\n",
    "\n",
    "        #backward pass to get gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        #update optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        #update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
    "    \n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    #print training result\n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    #evaluate\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    #f1 score\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_practicum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
