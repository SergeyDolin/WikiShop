{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. \n",
    "\n",
    "\n",
    "- –¶–µ–ª—å: –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. \n",
    "    - –ó–∞–¥–∞—á–∞: –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 –Ω–µ –º–µ–Ω—å—à–µ 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò–º–ø–æ—Ä—Ç—ã –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import random\n",
    "\n",
    "RANDOM_STATE = 1220\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laba-ml\\AppData\\Local\\Temp\\ipykernel_18496\\448593302.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(data_path_local, index_col=[0], parse_dates=[0])\n",
      "C:\\Users\\Laba-ml\\AppData\\Local\\Temp\\ipykernel_18496\\448593302.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df = pd.read_csv(data_path_local, index_col=[0], parse_dates=[0])\n"
     ]
    }
   ],
   "source": [
    "data_path_local = './toxic_comments.csv'\n",
    "data_path_web = 'https://code.s3.yandex.net/datasets/toxic_comments.csv'\n",
    "\n",
    "if os.path.exists(data_path_local):\n",
    "    df = pd.read_csv(data_path_local, index_col=[0], parse_dates=[0])\n",
    "elif requests.head(data_path_web).status_code == 200:\n",
    "    df = pd.read_csv(data_path_web, index_col=[0], parse_dates=[0])\n",
    "else:\n",
    "    print('Somthing is wrong')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_df(df):\n",
    "    print('------------------------------')\n",
    "    print('| –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö |')\n",
    "    print('------------------------------')\n",
    "    df.info()\n",
    "    print('------------------------------')\n",
    "    print('| –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ—á–µ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ |')\n",
    "    print('------------------------------')\n",
    "    print(df.head(10))\n",
    "    print('---------------------------------')\n",
    "    print('| –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ—á–µ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ |')\n",
    "    print('---------------------------------')\n",
    "    print(df.tail(10))\n",
    "    print('---------------------------')\n",
    "    print('| –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ |')\n",
    "    print('---------------------------')\n",
    "    print(df.describe())\n",
    "    print('--------------------')\n",
    "    print('| –°—É–º–º–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ |')\n",
    "    print('--------------------')\n",
    "    print(df.duplicated().sum())\n",
    "    print('--------------------------')\n",
    "    print('| –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ |')\n",
    "    print('--------------------------')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö |\n",
      "------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n",
      "------------------------------\n",
      "| –ü–µ—Ä–≤—ã–µ 10 —Å—Ç—Ä–æ—á–µ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ |\n",
      "------------------------------\n",
      "                                                text  toxic\n",
      "0  Explanation\\nWhy the edits made under my usern...      0\n",
      "1  D'aww! He matches this background colour I'm s...      0\n",
      "2  Hey man, I'm really not trying to edit war. It...      0\n",
      "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
      "4  You, sir, are my hero. Any chance you remember...      0\n",
      "5  \"\\n\\nCongratulations from me as well, use the ...      0\n",
      "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1\n",
      "7  Your vandalism to the Matt Shirvington article...      0\n",
      "8  Sorry if the word 'nonsense' was offensive to ...      0\n",
      "9  alignment on this subject and which are contra...      0\n",
      "---------------------------------\n",
      "| –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å—Ç—Ä–æ—á–µ–∫ –¥–∞—Ç–∞—Å–µ—Ç–∞ |\n",
      "---------------------------------\n",
      "                                                     text  toxic\n",
      "159441  \"\\nNo he did not, read it again (I would have ...      0\n",
      "159442  \"\\n Auto guides and the motoring press are not...      0\n",
      "159443  \"\\nplease identify what part of BLP applies be...      0\n",
      "159444  Catalan independentism is the social movement ...      0\n",
      "159445  The numbers in parentheses are the additional ...      0\n",
      "159446  \":::::And for the second time of asking, when ...      0\n",
      "159447  You should be ashamed of yourself \\n\\nThat is ...      0\n",
      "159448  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
      "159449  And it looks like it was actually you who put ...      0\n",
      "159450  \"\\nAnd ... I really don't think you understand...      0\n",
      "---------------------------\n",
      "| –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ |\n",
      "---------------------------\n",
      "               toxic\n",
      "count  159292.000000\n",
      "mean        0.101612\n",
      "std         0.302139\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         0.000000\n",
      "75%         0.000000\n",
      "max         1.000000\n",
      "--------------------\n",
      "| –°—É–º–º–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ |\n",
      "--------------------\n",
      "0\n",
      "--------------------------\n",
      "| –ö–æ–≤–∞—Ä–∏–∞—Ü–∏–æ–Ω–Ω–∞—è –º–∞—Ç—Ä–∏—Ü–∞ |\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "info_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    143106\n",
       "1     16186\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–í—ã–≤–æ–¥—ã**\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ –∏–º–µ—é—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤, –Ω–æ –∏–º–µ–µ—Ç—Å—è —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤, —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å–∏–ª—å–Ω–æ –º–µ–Ω—å—à–µ —á–µ–º –Ω–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö, —ç—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è. –ü—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∫ –æ–±—É—á–µ–Ω–∏—é –Ω–∞ BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–æ–±—å–µ–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é 85:15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.index.values,\n",
    "                                                   df['toxic'].values,\n",
    "                                                   test_size = 0.15,\n",
    "                                                   random_state = RANDOM_STATE,\n",
    "                                                   stratify = df['toxic'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>not_set</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic data_type\n",
       "0  Explanation\\nWhy the edits made under my usern...      0   not_set\n",
       "1  D'aww! He matches this background colour I'm s...      0   not_set\n",
       "2  Hey man, I'm really not trying to edit war. It...      0   not_set\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0   not_set\n",
       "4  You, sir, are my hero. Any chance you remember...      0   not_set"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['data_type'] = ['not_set'] * df.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_test, 'data_type'] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxic</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>121640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>21466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>13758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>2428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   text\n",
       "toxic data_type        \n",
       "0     train      121640\n",
       "      val         21466\n",
       "1     train       13758\n",
       "      val          2428"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['toxic', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',\n",
    "                                         do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].text.values,\n",
    "                                                add_special_tokens = True,\n",
    "                                                return_attention_mask = True,\n",
    "                                                pad_to_max_length = True,\n",
    "                                                max_length = 150,\n",
    "                                                return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_test = tokenizer.batch_encode_plus(df[df.data_type == 'test'].text.values,\n",
    "                                                return_attention_mask = True,\n",
    "                                                pad_to_max_length = True,\n",
    "                                                max_length = 150,\n",
    "                                                return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type == 'train'].toxic.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "\n",
    "labels_test = torch.tensor(df[df.data_type == 'test'].toxic.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞—Ç–∞—Å–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Ç–µ–Ω–∑–æ—Ä–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_test = TensorDataset(input_ids_test, \n",
    "                             attention_masks_test, \n",
    "                             labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135398\n",
      "23894\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels = 2,\n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"bert-base-uncased\",\n",
       "  \"architectures\": [\n",
       "    \"BertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.38.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size = BATCH_SIZE)\n",
    "\n",
    "dataloader_test = DataLoader(dataset_test,\n",
    "                              sampler = RandomSampler(dataset_test),\n",
    "                              batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\ds_practicum_env\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                 lr = 1e-5,\n",
    "                 eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                           num_warmup_steps = 0,\n",
    "                                           num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>    \n",
    "<div class=\"alert alert-info\">\n",
    "<h2> –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —Å—Ç—É–¥–µ–Ω—Ç–∞: <a class=\"tocSkip\"> </h2>\n",
    "\n",
    "<b>üëã: </b>–ü—Ä–∏–≤–µ—Ç! –ü–æ–¥—Å–∫–∞–∂–∏ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ª–∏ —è –ø–æ–Ω–∏–º–∞—é —á—Ç–æ –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –º–Ω–µ –Ω–∞ –¥–≤—É—Ö GPU –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –º–Ω–µ –Ω—É–∂–Ω–æ —ç—Ç–∞–ø—ã –≤ —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–∏–∂–µ –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –Ω–∞ DataParallel –∏–ª–∏ —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –Ω–∞–¥–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å?\n",
    "</div> \n",
    "\n",
    "<br/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader_val):\n",
    "\n",
    "    # model = torch.nn.DataParallel(model)\n",
    "    # model.cuda()\n",
    "    model.to('cuda')\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        #GPU\n",
    "        batch = tuple(b.to(DEVICE) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = RANDOM_STATE\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6088137f7da444983abd3675f8c6f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d6fe9d9ea44730b6e1d541be92475c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.15293168258516596\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4723974a4730423fa1e8f981df8c2e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.12771632477292094\n",
      "F1 Score (weighted): 0.9702840721892104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9b63329189479cb31c102dbbaf5a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.10247898710046266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c234855c0494dfc8294e1b9254f0c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.14249630847662487\n",
      "F1 Score (weighted): 0.970327939267206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed9a30b27904ec8975c3d7e6362ea70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.06290439604241552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41f48a75899f46e89582e518f6138a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.14235382314939413\n",
      "F1 Score (weighted): 0.9700696606182515\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822b032f31ab40c586dde8d7d195e21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.03475884376480129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e20b86487e8d4d26b386d55e7435b5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.21548801852643698\n",
      "F1 Score (weighted): 0.9695361297741453\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5cb6b55a9934a1a816b54ca7cc849a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.02050891817583922\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dd456096f34e11869bd2a61d330ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2619759149636354\n",
      "F1 Score (weighted): 0.9688069933223287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edebc0547a3e49b9b5cb31c5477f1103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.013548281249561814\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9ddbf0196a46cea2145f598a7d6e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.27898967495212845\n",
      "F1 Score (weighted): 0.9699396228227263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbaa251204ef4e9e9e7c25a4a7f2bd20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.008980870551279111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17593004c3644ba989aa5ea5de4a1eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3251788552956777\n",
      "F1 Score (weighted): 0.9702384084580061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa992963b1184808a2194125be9a28f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.006425782663726366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "504ffc069dcc4911ba371dc410cb47a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3227286861878535\n",
      "F1 Score (weighted): 0.9690289793180836\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f7c4d3f67d4709b3336c281d63d578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.0043341694204003635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83216ce5dab14d978f422277fac26f9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.312121919988347\n",
      "F1 Score (weighted): 0.9701087388687304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b748dcf37b3149ca8bc7f24f76acd01e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/33850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: 0.0025144718183257673\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042085d622f548c9a09fc1a8dc160d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/747 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.3357159744485248\n",
      "F1 Score (weighted): 0.9697820057917811\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "\n",
    "    # model = torch.nn.DataParallel(model)\n",
    "    # model.cuda()\n",
    "    model.to(DEVICE)\n",
    "    model.train()\n",
    "\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader_train, \n",
    "                        desc='Epoch {:1d}'.format(epoch), \n",
    "                        leave=False, \n",
    "                        disable=False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        model.zero_grad()\n",
    "\n",
    "        batch = tuple(b.to(DEVICE) for b in batch)\n",
    "\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "        loss_train_total +=loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
    "    \n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_test)\n",
    "    #f1 score\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Test (Validation) loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.to(DEVICE).state_dict(), 'C:\\\\Users\\\\Laba-ml\\\\LabaProjects\\\\BERT\\\\Model\\\\model.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_load = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "#                                                       num_labels = 2,\n",
    "#                                                       output_attentions = False,\n",
    "#                                                       output_hidden_states = False).to(DEVICE)\n",
    "# model_load.load_state_dict(torch.load('C:\\\\Users\\\\Laba-ml\\\\LabaProjects\\\\BERT\\\\Model\\\\model.torch'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –≤—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_test = evaluate(dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9697820057917811"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score_func(predictions, true_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¶–µ–ª—å—é –ø—Ä–æ–µ–∫—Ç–∞ –±—ã–ª–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–∞ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. \n",
    "\n",
    "–ó–∞–∫–∞–∑—á–∏–∫—É –±—ã–ª–æ –≤–∞–∂–Ω–æ:\n",
    "\n",
    "- –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ F1 >= 0.75\n",
    "\n",
    "–í—ã–ø–æ–ª–Ω–µ–Ω—ã–µ –∑–∞–¥–∞—á–∏:\n",
    "- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –æ–±–∑–æ—Ä –¥–∞–Ω–Ω—ã—Ö;\n",
    "- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –º–æ–¥–µ–ª–∏ BERT;\n",
    "- –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ;\n",
    "- –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–∏ –∏ –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Ç–µ—Å—Ç–æ–π –≤—ã–±–æ—Ä–∫–µ.\n",
    "\n",
    "**–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–µ –∏–º–µ—é—Ç –ø—Ä–æ–ø—É—Å–∫–æ–≤, –Ω–æ –∏–º–µ–µ—Ç—Å—è —Å–∏–ª—å–Ω—ã–π –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤, —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ —Å–∏–ª—å–Ω–æ –º–µ–Ω—å—à–µ —á–µ–º –Ω–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö, —ç—Ç–æ –º–æ–∂–µ—Ç –ø–æ–≤–ª–∏—è—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è. –ü—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è, –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –≤—ã–±–æ—Ä–∫–∞—Ö.\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –±—ã–ª–∏ —Ä–∞–∑–±–∏—Ç—ã –ø–æ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—é 85:15 –Ω–∞ —Ç–µ—Å—Ç–æ–≤—É—é –∏ –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É.\n",
    "\n",
    "\n",
    "**–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏**\n",
    "\n",
    "–ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏:\n",
    "\n",
    "- `BERT`\n",
    "    - F1 `0.969`\n",
    "\n",
    "–£—Å–ª–æ–≤–∏–µ –ø–æ –º–µ—Ç—Ä–∏–∫–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\n",
    "\n",
    "**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:** –î–ª—è –Ω–∞–∏–ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ —Ç–∞–∫–æ–µ –≤–æ–∑–º–æ–∂–Ω–æ), –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∏–∑–±–∞–≤–∏—Ç—å—Å—è –æ—Ç –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤, –¥–æ–ø–æ–ª–Ω–∏—Ç—å –≤—ã–±–æ—Ä–∫—É —Ç–æ–∫—Å–∏—á–Ω—ã–º–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_practicum_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
